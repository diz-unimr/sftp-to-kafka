/* GNU AFFERO GENERAL PUBLIC LICENSE  Version 3 (C)2024 Datenintegrationszentrum Fachbereich Medizin Philipps Universit√§t Marburg */
package de.unimarburg.diz.config;

import java.io.File;
import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.attribute.BasicFileAttributes;
import java.util.concurrent.CompletableFuture;
import lombok.extern.log4j.Log4j2;
import org.apache.kafka.common.errors.InvalidConfigurationException;
import org.json.JSONException;
import org.json.JSONObject;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Configuration;
import org.springframework.integration.dsl.IntegrationFlow;
import org.springframework.integration.redis.metadata.RedisMetadataStore;
import org.springframework.integration.support.MutableMessageBuilder;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.support.SendResult;
import org.springframework.messaging.Message;
import org.springframework.messaging.MessageChannel;
import org.springframework.messaging.MessageHeaders;
import org.springframework.util.StringUtils;

@Log4j2
// @Configuration
// @EnableConfigurationProperties(value = {SftpSourceConfig.class})
// @EnableIntegration
@Configuration
public class IntegrationTargets {

  private static String TARGET_TOPIC = "TEST-TOPICS-FTP";

  private final KafkaTemplate<String, String> kafkaTemplate;

  private final SourceConfig sourceConfig;

  private final KafkaProducerConfig kafkaCfg;
  private final RedisMetadataStore metaStore;
  private static final String LAST_MODIFIED = "LAST_MODIFIED";

  public IntegrationTargets(
      @Value("${app.target.topic}") String targetTopic,
      KafkaProducerConfig kafkaCfg,
      SourceConfig sourceConfig,
      RedisMetadataStore metaStore) {
    this.kafkaCfg = kafkaCfg;
    this.kafkaTemplate = kafkaCfg.kafkaTemplate();
    this.metaStore = metaStore;
    this.sourceConfig = sourceConfig;
    if (!StringUtils.hasText(targetTopic)) {
      throw new InvalidConfigurationException(
          "target output topic must be set! please check application configuration 'app.target.topic'");
    }
    TARGET_TOPIC = targetTopic;
  }

  public IntegrationFlow StreamFlowToKafka(MessageChannel source) {
    return IntegrationFlow.from(source)
        .handle((payload, headers) -> getMessageWithEnrichedLastModifiedHeader(payload, headers))
        .handle(
            (payload, headers) -> {
              final String kafkaMessageKey = getKafkaMessageKey(payload, headers);

              final String s = metaStore.get(kafkaMessageKey);

              if (s != null && s.equals(headers.get(LAST_MODIFIED).toString())) {
                log.info(
                    "skipping message id '{}' since it has been processed before with timestamp {}",
                    headers.getId(),
                    headers.get("LAST_MODIFIED"));
                return null;
              }

              final CompletableFuture<SendResult<String, String>> send =
                  kafkaTemplate.send(
                      TARGET_TOPIC,
                      null,
                      headers.getTimestamp(),
                      kafkaMessageKey,
                      payload.toString());
              send.whenComplete(
                  (res, ex) -> {
                    if (ex != null) {
                      log.error("storing message at KAFKA failed", ex);
                      throw new RuntimeException("could not store message into Kafka");
                    }
                    metaStore.put(kafkaMessageKey, headers.get("LAST_MODIFIED").toString());

                    log.info(
                        "Message SUCCESSFULLY STORED AT KAFKA !{}",
                        res.getRecordMetadata().toString());
                  });
              return null;
            })
        .get();
  }

  private static Message<Object> getMessageWithEnrichedLastModifiedHeader(
      Object message, MessageHeaders headers) {
    try {
      Message<Object> lastModified = null;
      if (headers.containsKey("file_originalFile")) {
        final File fileOrigFile = new File(headers.get("file_originalFile").toString());

        BasicFileAttributes attr =
            Files.readAttributes(fileOrigFile.toPath(), BasicFileAttributes.class);
        lastModified = buildMessageWithLastModifiedHeader(message, attr.lastModifiedTime());
        lastModified.getHeaders().putAll(headers);
        return lastModified;
      } else if (headers.containsKey("file_remoteFileInfo")) {
        var modifiedValue =
            new JSONObject(headers.get("file_remoteFileInfo").toString()).get("modified");
        lastModified = buildMessageWithLastModifiedHeader(message, modifiedValue);
        lastModified.getHeaders().putAll(headers);
      }
      return lastModified;
    } catch (IOException e) {
      throw new RuntimeException(e);
    }
  }

  private static Message<Object> buildMessageWithLastModifiedHeader(
      Object message, Object lastModified) {
    var builder =
        MutableMessageBuilder.withPayload(message).setHeader("LAST_MODIFIED", lastModified);
    return builder.build();
  }

  private String getKafkaMessageKey(Object payload, MessageHeaders headers) {
    String kafkaMessageKey;
    if (StringUtils.hasText(sourceConfig.propertyAsId())) {
      kafkaMessageKey = tryGetPayloadInternalId(payload.toString());
    } else {
      kafkaMessageKey = headers.getId().toString();
    }
    return kafkaMessageKey;
  }

  private String tryGetPayloadInternalId(String messageAsString) {

    var idFromJsonPath = JsonUtil.getPropValue(sourceConfig.propertyAsId(), messageAsString);
    if (idFromJsonPath == null) {
      throw new JSONException(
          "element id from Json with jsonpath " + sourceConfig.propertyAsId() + " is missing! ");
    }

    return idFromJsonPath.toString();
  }
}
